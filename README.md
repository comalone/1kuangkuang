# 手势识别截图与 AI 智能分析系统

这是一个基于 **MediaPipe** 和 **FastAPI** 开发的智能交互系统。它允许用户通过手势在视频流中框选特定区域进行截图，并自动调用 **阿里云 DashScope (Qwen-VL)** 大模型对截图内容进行深度分析。

## 🌟 核心功能

-   **手势框选截图**: 
    -   使用食指指向（Pointer）触发检测。
    -   保持静止 1 秒设定起始点。
    -   移动食指划定矩形区域。
    -   再次保持静止 1 秒自动执行截图。
-   **AI 智能分析**: 截图完成后自动上传至云端，利用 `qwen-vl-plus` 模型分析图片内容并实时返回结果。
-   **无感交互**: 在结果页面比划 "OK" 手势即可自动重置状态并返回拍摄界面，无需鼠标操作。
-   **多摄像头支持**: 支持 ESP32-CAM 远程推流或本地 USB 摄像头切换。
-   **实时反馈**: 结果页面提供左下角实时小窗预览，确保交互连贯性。
-   **多模式切换**: 支持通过 `prompts.json` 配置多种 AI 分析角色（如解题助手、爆文创作、剧本扩写等）。

## 🛠️ 技术栈

-   **后端**: FastAPI (Python 3.8+)
-   **视觉处理**: OpenCV, MediaPipe (Lite 模型优化)
-   **AI 能力**: 阿里云 DashScope SDK (Qwen-VL)
-   **前端**: 原生 HTML5 / JavaScript (支持异步轮询与状态机同步)

## 🚀 快速开始

### 1. 安装依赖
```bash
pip install fastapi uvicorn opencv-python mediapipe numpy requests dashscope
```

### 2. 配置 API Key
在环境变量中填入您的阿里云 DASHSCOPE_API_KEY


### 3. 运行服务
```bash
python service.py
```
访问地址：`http://localhost:8000`

## 🎮 操作指南

| 动作 | 触发效果 | 视觉反馈 |
| :--- | :--- | :--- |
| **伸出食指** | 进入检测模式 | 状态切换为 `DETECTING` |
| **保持静止 1s** | 锁定起始点 | 出现绿色矩形框 |
| **移动食指** | 调整截图区域 | 矩形框随手指实时拉伸 |
| **再次静止 1s** | 执行截图并上传 | 绿框消失，自动跳转结果页 |
| **比划 "OK"** | (结果页) 返回拍摄 | 自动重置状态机并跳转回主页 |

## 🎨 AI 分析模式

系统内置了多种 AI 提示词模式，定义在 `prompts.json` 中：

-   **💡 解题思路**: 识别题目并提供步骤清晰的解题指导。
-   **🧠 深度理解**: 解析图片背后的逻辑、背景及情感含义。
-   **✨ 文章润色**: 识别文字并进行专业级润色优化。
-   **🔥 爆文创作**: 基于图片生成小红书/微博风格的爆款文案。
-   **🛡️ 内容审核**: 检查图片内容的合规性与逻辑错误。
-   **🎓 论文精修**: 优化学术论文片段的表达与逻辑。
-   **🎭 剧本扩写**: 根据画面扩写电影级剧本情节。

## 📂 项目结构

```text
├── service.py       # FastAPI 后端逻辑、手势识别与 AI 调用
├── screenshot.html      # 主拍摄界面
├── screenshot_result.html # 结果展示与 AI 分析界面
├── prompts.json         # AI 提示词配置文件
├── uploads/             # 截图文件存储目录
└── README.md            # 项目说明文档
```


## 📄 许可证
本项目基于 Apache v2 许可证开源。
